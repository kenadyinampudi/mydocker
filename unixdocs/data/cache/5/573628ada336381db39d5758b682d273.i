a:255:{i:0;a:3:{i:0;s:14:"document_start";i:1;a:0:{}i:2;i:0;}i:1;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:14:"STILL IN DRAFT";i:1;i:1;i:2;i:1;}i:2;i:1;}i:2;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:1;}i:2;i:1;}i:3;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:31;}i:4;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:41:"SAP System Refresh using Storage Snapshot";i:1;i:1;i:2;i:31;}i:2;i:31;}i:5;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:1;}i:2;i:31;}i:6;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:31;}i:7;a:3:{i:0;s:11:"strong_open";i:1;a:0:{}i:2;i:88;}i:8;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:208:" Some documented commands are PowerShell commands. Connect to the respective vCenter with your AD credentials and execute carefully, it is a very powerful tool - you can do a lot of damage if you have rights ";}i:2;i:90;}i:9;a:3:{i:0;s:12:"strong_close";i:1;a:0:{}i:2;i:298;}i:10;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:300;}i:11;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:300;}i:12;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:144:"This document will give one an overview of how to perform a SAP system copy using storage snapshot, when the system is running Linux on VMware. ";}i:2;i:302;}i:13;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:446;}i:14;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:446;}i:15;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:95:"If you have powerCLI modules added to your PowerShell environment - Use these steps to connect ";}i:2;i:448;}i:16;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:544;}i:17;a:3:{i:0;s:10:"listo_open";i:1;a:0:{}i:2;i:544;}i:18;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:544;}i:19;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:544;}i:20;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:19:" Connect to vCenter";}i:2;i:548;}i:21;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:75:"Connect-VIServer -server cdcpilvc005.pt.int.tenneco.com -User amer\x1naveka";i:1;N;i:2;N;}i:2;i:572;}i:22;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:572;}i:23;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:93:"Make sure to use the Tenneco domain username and password when it prompts for the credentials";}i:2;i:655;}i:24;a:3:{i:0;s:14:"monospace_open";i:1;a:0:{}i:2;i:748;}i:25;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:22:"<domain>\<accountname>";}i:2;i:750;}i:26;a:3:{i:0;s:15:"monospace_close";i:1;a:0:{}i:2;i:772;}i:27;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:78:" and supply credentials.  If powerCLI is not installed and configured, follow ";}i:2;i:774;}i:28;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:29:"unix:install_powercli_desktop";i:1;s:4:"this";}i:2;i:852;}i:29;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:46:" documentation to install & configure powerCLI";}i:2;i:890;}i:30;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:936;}i:31;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:936;}i:32;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:936;}i:33;a:3:{i:0;s:11:"listo_close";i:1;a:0:{}i:2;i:936;}i:34;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:939;}i:35;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:5:"Scope";i:1;i:2;i:2;i:939;}i:2;i:939;}i:36;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:939;}i:37;a:3:{i:0;s:10:"listo_open";i:1;a:0:{}i:2;i:957;}i:38;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:957;}i:39;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:957;}i:40;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:61:" In this case, we are performing a system copy of RLP to RLS.";}i:2;i:961;}i:41;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1022;}i:42;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1022;}i:43;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1022;}i:44;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1022;}i:45;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:93:" RLP is the production server and is on cdcvillpx016, and is hosted on the PROD-SUSE1 Cluster";}i:2;i:1026;}i:46;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1119;}i:47;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1119;}i:48;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1119;}i:49;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1119;}i:50;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:90:" RLS is the sandbox server and is on cdcvillpx008, and is hosted on NON-PROD-SUSE1 Cluster";}i:2;i:1123;}i:51;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1213;}i:52;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1213;}i:53;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1213;}i:54;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1213;}i:55;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:48:" During a system copy or refresh, SAP teams and ";}i:2;i:1217;}i:56;a:3:{i:0;s:7:"acronym";i:1;a:1:{i:0;s:3:"DBA";}i:2;i:1265;}i:57;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:186:" only needs the sapdata filesystems.  In case, they want to completely create a new cloned server, there are other documents that explains this process and this method shouldn't be used.";}i:2;i:1268;}i:58;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:1454;}i:59;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:1454;}i:60;a:3:{i:0;s:11:"listo_close";i:1;a:0:{}i:2;i:1454;}i:61;a:3:{i:0;s:10:"table_open";i:1;a:3:{i:0;i:7;i:1;i:2;i:2;i:1456;}i:2;i:1455;}i:62;a:3:{i:0;s:13:"tablerow_open";i:1;a:0:{}i:2;i:1455;}i:63;a:3:{i:0;s:16:"tableheader_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:1455;}i:64;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:13:"Source Server";}i:2;i:1457;}i:65;a:3:{i:0;s:17:"tableheader_close";i:1;a:0:{}i:2;i:1470;}i:66;a:3:{i:0;s:16:"tableheader_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:1470;}i:67;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:21:"Source VMware cluster";}i:2;i:1471;}i:68;a:3:{i:0;s:17:"tableheader_close";i:1;a:0:{}i:2;i:1492;}i:69;a:3:{i:0;s:16:"tableheader_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:1492;}i:70;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:10:"Source SID";}i:2;i:1493;}i:71;a:3:{i:0;s:17:"tableheader_close";i:1;a:0:{}i:2;i:1503;}i:72;a:3:{i:0;s:16:"tableheader_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:1503;}i:73;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:13:"Target server";}i:2;i:1504;}i:74;a:3:{i:0;s:17:"tableheader_close";i:1;a:0:{}i:2;i:1517;}i:75;a:3:{i:0;s:16:"tableheader_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:1517;}i:76;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:21:"Target VMware cluster";}i:2;i:1518;}i:77;a:3:{i:0;s:17:"tableheader_close";i:1;a:0:{}i:2;i:1539;}i:78;a:3:{i:0;s:16:"tableheader_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:1539;}i:79;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:10:"Target SID";}i:2;i:1540;}i:80;a:3:{i:0;s:17:"tableheader_close";i:1;a:0:{}i:2;i:1550;}i:81;a:3:{i:0;s:16:"tableheader_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:1550;}i:82;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:16:"Target ESXi Host";}i:2;i:1551;}i:83;a:3:{i:0;s:17:"tableheader_close";i:1;a:0:{}i:2;i:1567;}i:84;a:3:{i:0;s:14:"tablerow_close";i:1;a:0:{}i:2;i:1568;}i:85;a:3:{i:0;s:13:"tablerow_open";i:1;a:0:{}i:2;i:1568;}i:86;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:4:"left";i:2;i:1;}i:2;i:1568;}i:87;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:14:"cdcvillpx016  ";}i:2;i:1570;}i:88;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:1584;}i:89;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:4:"left";i:2;i:1;}i:2;i:1584;}i:90;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:17:"PROD-SUSE1       ";}i:2;i:1585;}i:91;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:1602;}i:92;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:4:"left";i:2;i:1;}i:2;i:1602;}i:93;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:10:"RLP       ";}i:2;i:1603;}i:94;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:1613;}i:95;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;N;i:2;i:1;}i:2;i:1613;}i:96;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:12:"cdcvillpx008";}i:2;i:1614;}i:97;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:1626;}i:98;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:4:"left";i:2;i:1;}i:2;i:1626;}i:99;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:20:"NON-PROD-SUSE1      ";}i:2;i:1627;}i:100;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:1647;}i:101;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:4:"left";i:2;i:1;}i:2;i:1647;}i:102;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:10:"RLS       ";}i:2;i:1648;}i:103;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:1658;}i:104;a:3:{i:0;s:14:"tablecell_open";i:1;a:3:{i:0;i:1;i:1;s:4:"left";i:2;i:1;}i:2;i:1658;}i:105;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:35:"cdcpilvm103.pt.int.tenneco.com     ";}i:2;i:1659;}i:106;a:3:{i:0;s:15:"tablecell_close";i:1;a:0:{}i:2;i:1694;}i:107;a:3:{i:0;s:14:"tablerow_close";i:1;a:0:{}i:2;i:1695;}i:108;a:3:{i:0;s:11:"table_close";i:1;a:1:{i:0;i:1695;}i:2;i:1695;}i:109;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:1697;}i:110;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:9:"Pre-steps";i:1;i:2;i:2;i:1697;}i:2;i:1697;}i:111;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:1697;}i:112;a:3:{i:0;s:10:"listo_open";i:1;a:0:{}i:2;i:1719;}i:113;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:1719;}i:114;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:1719;}i:115;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:1723;}i:116;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:23:"unix:powercli_disk_info";i:1;s:23:"Identify the Datastores";}i:2;i:1724;}i:117;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:131:" that needs to be replicated. Using powerCLI is easier to get the the list of all disks presented to the source system (production)";}i:2;i:1775;}i:118;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:2735:"Get-VMDiskAndRDM -vmName CDCPILLX016 -ShowVMDKDatastorePath | ft -a

VMName      HardDiskName ScsiId DeviceDisplayName SizeGB ScsiCanonicalName VMDKDStorePath                                     
------      ------------ ------ ----------------- ------ ----------------- --------------                                     
CDCPILLX016 Hard disk 1  0:0                          50                   [PROD-SUSE1-PT-015] CDCPILLX016/CDCPILLX016_3.vmdk 
CDCPILLX016 Hard disk 2  0:1                          50                   [PROD-SUSE1-PT-015] CDCPILLX016/CDCPILLX016_1.vmdk 
CDCPILLX016 Hard disk 3  0:2                         200                   [PROD-SUSE1-PT-020] CDCPILLX016/CDCPILLX016_2.vmdk 
CDCPILLX016 Hard disk 4  0:3                         500                   [PROD-SUSE1-PT-250] CDCPILLX016/CDCPILLX016_4.vmdk 
CDCPILLX016 Hard disk 5  0:4                          40                   [PROD-SUSE1-PT-015] CDCPILLX016/CDCPILLX016_5.vmdk 
CDCPILLX016 Hard disk 6  0:5                          50                   [PROD-SUSE1-PT-015] CDCPILLX016/CDCPILLX016_6.vmdk 
CDCPILLX016 Hard disk 7  0:6                         600                   [PROD-SUSE1-PT-254] CDCPILLX016/CDCPILLX016_7.vmdk 
CDCPILLX016 Hard disk 8  0:8                         650                   [PROD-SUSE1-PT-015] CDCPILLX016/CDCPILLX016_8.vmdk 
CDCPILLX016 Hard disk 9  0:9                         100                   [PROD-SUSE1-PT-015] CDCPILLX016/CDCPILLX016_9.vmdk 
CDCPILLX016 Hard disk 10 0:10                        710                   [PROD-SUSE1-PT-015] CDCPILLX016/CDCPILLX016_10.vmdk
CDCPILLX016 Hard disk 11 0:11                        800                   [PROD-SUSE1-PT-015] CDCPILLX016/CDCPILLX016_11.vmdk
CDCPILLX016 Hard disk 12 0:12                        550                   [PROD-SUSE1-PT-015] CDCPILLX016/CDCPILLX016_12.vmdk
CDCPILLX016 Hard disk 13 0:13                        500                   [PROD-SUSE1-PT-014] CDCPILLX016/CDCPILLX016_15.vmdk
CDCPILLX016 Hard disk 14 0:14                        550                   [PROD-SUSE1-PT-014] CDCPILLX016/CDCPILLX016_14.vmdk
CDCPILLX016 Hard disk 15 0:15                         50                   [PROD-SUSE1-PT-015] CDCPILLX016/CDCPILLX016.vmdk   
CDCPILLX016 Hard disk 16 1:0                         250                   [PROD-SUSE1-PT-250] CDCPILLX016/CDCPILLX016_13.vmdk
CDCPILLX016 Hard disk 17 1:1                          80                   [PROD-SUSE1-PT-015] CDCPILLX016/CDCPILLX016_16.vmdk
CDCPILLX016 Hard disk 18 1:2                         680                   [PROD-SUSE1-PT-020] CDCPILLX016/CDCPILLX016_17.vmdk
CDCPILLX016 Hard disk 19 1:3                         450                   [PROD-SUSE1-PT-021] CDCPILLX016/CDCPILLX016.vmdk   ";i:1;N;i:2;N;}i:2;i:1911;}i:119;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:4654;}i:120;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:4654;}i:121;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:4654;}i:122;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:4654;}i:123;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:120:" Login to the source systems (RLP in this case= and get the disk scsi number and the disks in the sapdata volume groups.";}i:2;i:4658;}i:124;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:46:"lsscsi
df -h |grep sapdata
vgs
lvs |grep sapvg";i:1;N;i:2;N;}i:2;i:4783;}i:125;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:4783;}i:126;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:13:"SAMPLE OUTPUT";}i:2;i:4837;}i:127;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:4855;}i:128;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:2284:"cdcpillx016:~ # lsscsi
[0:0:0:0]    disk    VMware   Virtual disk     2.0   /dev/sda
[0:0:1:0]    disk    VMware   Virtual disk     2.0   /dev/sdb
[0:0:2:0]    disk    VMware   Virtual disk     2.0   /dev/sdc
[0:0:3:0]    disk    VMware   Virtual disk     2.0   /dev/sdd
[0:0:4:0]    disk    VMware   Virtual disk     2.0   /dev/sde
[0:0:5:0]    disk    VMware   Virtual disk     2.0   /dev/sdf
[0:0:6:0]    disk    VMware   Virtual disk     2.0   /dev/sdg
[0:0:8:0]    disk    VMware   Virtual disk     2.0   /dev/sdh
[0:0:9:0]    disk    VMware   Virtual disk     2.0   /dev/sdi
[0:0:10:0]   disk    VMware   Virtual disk     2.0   /dev/sdj
[0:0:11:0]   disk    VMware   Virtual disk     2.0   /dev/sdk
[0:0:12:0]   disk    VMware   Virtual disk     2.0   /dev/sdl
[0:0:13:0]   disk    VMware   Virtual disk     2.0   /dev/sdm
[0:0:14:0]   disk    VMware   Virtual disk     2.0   /dev/sdn
[0:0:15:0]   disk    VMware   Virtual disk     2.0   /dev/sdo
[1:0:0:0]    disk    VMware   Virtual disk     2.0   /dev/sdp
[1:0:1:0]    disk    VMware   Virtual disk     2.0   /dev/sdq
[1:0:2:0]    disk    VMware   Virtual disk     2.0   /dev/sdr
[1:0:3:0]    disk    VMware   Virtual disk     2.0   /dev/sds
[2:0:0:0]    cd/dvd  NECVMWar VMware SATA CD00 1.00  /dev/sr0
cdcpillx016:~ # df -h |grep sapdata
/dev/mapper/sapvg-sapdata1lv     890G  829G   17G  99% /oracle/RLP/sapdata1
/dev/mapper/sapvg-sapdata3lv     868G  813G   12G  99% /oracle/RLP/sapdata3
/dev/mapper/sapvg-sapdata4lv     868G  789G   36G  96% /oracle/RLP/sapdata4
/dev/mapper/sapvg-sapdata2lv     1.2T  1.1T   17G  99% /oracle/RLP/sapdata2
/dev/mapper/sapvg-sapdata6lv     1.2T  466G  664G  42% /oracle/RLP/sapdata6
/dev/mapper/sapvg-sapdata5lv     669G  611G   29G  96% /oracle/RLP/sapdata5
cdcpillx016:~ # pvs |grep sapvg
  /dev/sdd   sapvg    lvm2 a--  500.00g       0
  /dev/sdg   sapvg    lvm2 a--  600.00g       0
  /dev/sdh   sapvg    lvm2 a--  650.00g       0
  /dev/sdj   sapvg    lvm2 a--  710.00g   32.97g
  /dev/sdk   sapvg    lvm2 a--  800.00g       0
  /dev/sdl   sapvg    lvm2 a--  550.00g       0
  /dev/sdm   sapvg    lvm2 a--  500.00g       0
  /dev/sdn   sapvg    lvm2 a--  550.00g       0
  /dev/sdr   sapvg    lvm2 a--  680.00g       0
  /dev/sds   sapvg    lvm2 a--  450.00g  229.99g
cdcpillx016:~ #";i:1;N;i:2;N;}i:2;i:4855;}i:129;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:7147;}i:130;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:7147;}i:131;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:7147;}i:132;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:7147;}i:133;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:90:" Identify the disks that matters to us.  Make sure to use the correct sapdata volume group";}i:2;i:7151;}i:134;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:76:"for disk in `pvs |grep sapvg |awk '{print $1}'`
do
lsscsi |grep -w disk
done";i:1;N;i:2;N;}i:2;i:7246;}i:135;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:7246;}i:136;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:13:"SAMPLE OUTPUT";}i:2;i:7330;}i:137;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:7348;}i:138;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:726:"cdcpillx016:~ # for i in `pvs |grep sapvg |awk '{print $1}'`
> do
> lsscsi |grep $i
> done
[0:0:3:0]    disk    VMware   Virtual disk     2.0   /dev/sdd
[0:0:6:0]    disk    VMware   Virtual disk     2.0   /dev/sdg
[0:0:8:0]    disk    VMware   Virtual disk     2.0   /dev/sdh
[0:0:10:0]   disk    VMware   Virtual disk     2.0   /dev/sdj
[0:0:11:0]   disk    VMware   Virtual disk     2.0   /dev/sdk
[0:0:12:0]   disk    VMware   Virtual disk     2.0   /dev/sdl
[0:0:13:0]   disk    VMware   Virtual disk     2.0   /dev/sdm
[0:0:14:0]   disk    VMware   Virtual disk     2.0   /dev/sdn
[1:0:2:0]    disk    VMware   Virtual disk     2.0   /dev/sdr
[1:0:3:0]    disk    VMware   Virtual disk     2.0   /dev/sds
cdcpillx016:~ #";i:1;N;i:2;N;}i:2;i:7348;}i:139;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:8082;}i:140;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:8082;}i:141;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:8082;}i:142;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:8082;}i:143;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:165:" From the combination of step 1 and the above step, we need to identify the datastores that hosts the physical volumes.  We can see that on controller 0, disks with ";}i:2;i:8086;}i:144;a:3:{i:0;s:7:"acronym";i:1;a:1:{i:0;s:4:"SCSI";}i:2;i:8251;}i:145;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:57:" ID 3,6,8,10,11,12,13,14 and on controller 1, disks with ";}i:2;i:8255;}i:146;a:3:{i:0;s:7:"acronym";i:1;a:1:{i:0;s:4:"SCSI";}i:2;i:8312;}i:147;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:52:" ID of 2 & 3 are used.  Please note that disks with ";}i:2;i:8316;}i:148;a:3:{i:0;s:7:"acronym";i:1;a:1:{i:0;s:4:"SCSI";}i:2;i:8368;}i:149;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:92:" ID 3 is not necessarily the same as 'Hard Disk 3'.  The following mapping can be derived.  ";}i:2;i:8372;}i:150;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:1356:"/dev/sdd	CDCPILLX016 Hard disk 4  0:3                         500                   [PROD-SUSE1-PT-250] CDCPILLX016/CDCPILLX016_4.vmdk 
/dev/sdg	CDCPILLX016 Hard disk 7  0:6                         600                   [PROD-SUSE1-PT-254] CDCPILLX016/CDCPILLX016_7.vmdk 
/dev/sdh	CDCPILLX016 Hard disk 8  0:8                         650                   [PROD-SUSE1-PT-015] CDCPILLX016/CDCPILLX016_8.vmdk 
/dev/sdj	CDCPILLX016 Hard disk 10 0:10                        710                   [PROD-SUSE1-PT-015] CDCPILLX016/CDCPILLX016_10.vmdk
/dev/sdk	CDCPILLX016 Hard disk 11 0:11                        800                   [PROD-SUSE1-PT-015] CDCPILLX016/CDCPILLX016_11.vmdk
/dev/sdl	CDCPILLX016 Hard disk 12 0:12                        550                   [PROD-SUSE1-PT-015] CDCPILLX016/CDCPILLX016_12.vmdk
/dev/sdm	CDCPILLX016 Hard disk 13 0:13                        500                   [PROD-SUSE1-PT-014] CDCPILLX016/CDCPILLX016_15.vmdk
/dev/sdn	CDCPILLX016 Hard disk 14 0:14                        550                   [PROD-SUSE1-PT-014] CDCPILLX016/CDCPILLX016_14.vmdk
/dev/sdr	CDCPILLX016 Hard disk 18 1:2                         680                   [PROD-SUSE1-PT-020] CDCPILLX016/CDCPILLX016_17.vmdk
/dev/sds	CDCPILLX016 Hard disk 19 1:3                         450                   [PROD-SUSE1-PT-021] CDCPILLX016/CDCPILLX016.vmdk";i:1;N;i:2;N;}i:2;i:8469;}i:151;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:8469;}i:152;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:65:"Or in summary, the following datastores needs to be snapmirrored.";}i:2;i:9833;}i:153;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:9903;}i:154;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:108:"
PROD-SUSE1-PT-250
PROD-SUSE1-PT-254
PROD-SUSE1-PT-015
PROD-SUSE1-PT-014
PROD-SUSE1-PT-020
PROD-SUSE1-PT-021";i:1;N;i:2;N;}i:2;i:9903;}i:155;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:10019;}i:156;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:10019;}i:157;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:10019;}i:158;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:10019;}i:159;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:10023;}i:160;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:29:"unix:powercli_datastore_cname";i:1;s:27:"Identify the canonical name";}i:2;i:10024;}i:161;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:49:" to be provided to the storage team from PowerCLI";}i:2;i:10085;}i:162;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:439:"Name              CanonicalName                       
----              -------------                       
PROD-SUSE1-PT-015 naa.624a9370388f90324cca45010001143b
PROD-SUSE1-PT-020 naa.624a9370388f90324cca4501009a2edc
PROD-SUSE1-PT-250 naa.624a9370388f90324cca450100737b93
PROD-SUSE1-PT-254 naa.624a9370388f90324cca4501004d2a59
PROD-SUSE1-PT-014 naa.624a9370388f90324cca45010001143a
PROD-SUSE1-PT-021 naa.624a9370388f90324cca4501009a2edd";i:1;N;i:2;N;}i:2;i:10139;}i:163;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:10139;}i:164;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:349:"It is very important to inform them in which cluster the snap mirrored copy of these disks should be presented.  This would be same cluster as the target system. It is also a good idea to give the list of VM Hosts in the cluster.  Note that the server cdcpillx008a is the name of the target VM (as the VM name in VCenter) which is being refreshed.  ";}i:2;i:10586;}i:165;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:10940;}i:166;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:38:"Get-Cluster NON-PROD-SUSE1 |Get-VMHost";i:1;N;i:2;N;}i:2;i:10940;}i:167;a:3:{i:0;s:6:"p_open";i:1;a:0:{}i:2;i:10940;}i:168;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:13:"SAMPLE OUTPUT";}i:2;i:10986;}i:169;a:3:{i:0;s:7:"p_close";i:1;a:0:{}i:2;i:11004;}i:170;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:2050:"Name                 ConnectionState PowerState NumCpu CpuUsageMhz CpuTotalMhz   MemoryUsageGB   MemoryTotalGB Version
----                 --------------- ---------- ------ ----------- -----------   -------------   ------------- -------
cdcpilvm161.pt.in... Connected       PoweredOn      40        3076       87760         490.965         767.892   6.5.0
cdcpilvm135.pt.in... Connected       PoweredOn      20         925       59980         162.186         383.932   6.5.0
cdcpilvm108.pt.in... Connected       PoweredOn      20        4263       59980         212.648         383.932   6.5.0
cdcpilvm153.pt.in... Connected       PoweredOn      20        1242       59980         292.172         383.932   6.5.0
cdcpilvm214.pt.in... Connected       PoweredOn      20        4605       60000         180.936         383.932   6.5.0
cdcpilvm109.pt.in... Connected       PoweredOn      20        4993       59980         223.685         383.932   6.5.0
cdcpilvm129.pt.in... Connected       PoweredOn      20       17128       59980         153.677         383.932   6.5.0
cdcpilvm162.pt.in... Connected       PoweredOn      20        1072       59980         195.592         383.932   6.5.0
cdcpilvm160.pt.in... Connected       PoweredOn      40        5869       87760         512.184         767.892   6.5.0
cdcpilvm220.pt.in... Connected       PoweredOn      40        6862       87760         627.423         767.891   6.7.0
cdcpilvm116.pt.in... Connected       PoweredOn      20        3497       59980          93.262         383.932   6.5.0
cdcpilvm218.pt.in... Connected       PoweredOn      40        5696       87760         621.977         767.825   6.7.0
cdcpilvm130.pt.in... Connected       PoweredOn      20         908       59980         181.689         383.932   6.5.0
cdcpilvm103.pt.in... Connected       PoweredOn      20        1090       59980         284.787         383.932   6.5.0
cdcpilvm104.pt.in... Connected       PoweredOn      20        1447       59980         140.949         383.932   6.5.0



PS C:\WINDOWS\system32> ";i:1;N;i:2;N;}i:2;i:11004;}i:171;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:13062;}i:172;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:13062;}i:173;a:3:{i:0;s:11:"listo_close";i:1;a:0:{}i:2;i:13062;}i:174;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:13064;}i:175;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:29:"Actions by Storage Team & DBA";i:1;i:2;i:2;i:13064;}i:2;i:13064;}i:176;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:13064;}i:177;a:3:{i:0;s:10:"listo_open";i:1;a:0:{}i:2;i:13105;}i:178;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:13105;}i:179;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:13105;}i:180;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:85:" The storage creates the mapping and zoning and performs the initial sync to new LUNs";}i:2;i:13109;}i:181;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:13194;}i:182;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:13194;}i:183;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:13194;}i:184;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:13194;}i:185;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:36:" Once the initial sync is complete, ";}i:2;i:13198;}i:186;a:3:{i:0;s:7:"acronym";i:1;a:1:{i:0;s:3:"DBA";}i:2;i:13234;}i:187;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:34:" puts the database in backup mode.";}i:2;i:13237;}i:188;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:13271;}i:189;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:13271;}i:190;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:13271;}i:191;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:13271;}i:192;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:38:" Storage Team performs the final sync ";}i:2;i:13275;}i:193;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:13313;}i:194;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:13313;}i:195;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:13313;}i:196;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:13313;}i:197;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:13317;}i:198;a:3:{i:0;s:7:"acronym";i:1;a:1:{i:0;s:3:"DBA";}i:2;i:13318;}i:199;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:51:" puts the database back to normal R/W operations.  ";}i:2;i:13321;}i:200;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:13372;}i:201;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:13372;}i:202;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:13372;}i:203;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:13372;}i:204;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:97:" Storage presents the LUN to the target Cluster and will provide details in the following format.";}i:2;i:13376;}i:205;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:815:"cdc-v-non-prod-suse1_non-prod-suse1-nr-001  4T    cdc-v-prod-suse1_prod-suse1-pt-014  2023-01-17 05:15:47 CST  388F90324CCA450100D9B630
cdc-v-non-prod-suse1_non-prod-suse1-nr-002  4T    cdc-v-prod-suse1_prod-suse1-pt-015  2023-01-17 05:15:47 CST  388F90324CCA450100D9B631
cdc-v-non-prod-suse1_non-prod-suse1-nr-003  4T    cdc-v-prod-suse1_prod-suse1-pt-020  2023-01-17 05:15:47 CST  388F90324CCA450100D9B632
cdc-v-non-prod-suse1_non-prod-suse1-nr-004  4T    cdc-v-prod-suse1_prod-suse1-pt-021  2023-01-17 05:15:47 CST  388F90324CCA450100D9B633
cdc-v-non-prod-suse1_non-prod-suse1-nr-005  4T    cdc-v-prod-suse1_prod-suse1-pt-250  2023-01-17 05:15:47 CST  388F90324CCA450100D9B634
cdc-v-non-prod-suse1_non-prod-suse1-nr-006  4T    cdc-v-prod-suse1_prod-suse1-pt-254  2023-01-17 05:15:47 CST  388F90324CCA450100D9B635";i:1;N;i:2;N;}i:2;i:13478;}i:206;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:14301;}i:207;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:14301;}i:208;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:14301;}i:209;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:14301;}i:210;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:54:" SAP and Databse on the target should now be shutdown.";}i:2;i:14305;}i:211;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:14359;}i:212;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:14359;}i:213;a:3:{i:0;s:11:"listo_close";i:1;a:0:{}i:2;i:14359;}i:214;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:14361;}i:215;a:3:{i:0;s:6:"header";i:1;a:3:{i:0;s:21:"Refresh Steps by Unix";i:1;i:2;i:2;i:14361;}i:2;i:14361;}i:216;a:3:{i:0;s:12:"section_open";i:1;a:1:{i:0;i:2;}i:2;i:14361;}i:217;a:3:{i:0;s:10:"listo_open";i:1;a:0:{}i:2;i:14394;}i:218;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:14394;}i:219;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:14394;}i:220;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:41:" Confirm that SAP & Database are shutdown";}i:2;i:14398;}i:221;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:14439;}i:222;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:14439;}i:223;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:14439;}i:224;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:14439;}i:225;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:91:" On the target system, in this case, cdcpillv008, dismount the existing sapdata filesystems";}i:2;i:14443;}i:226;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:72:"for fs in `df -h |grep sapdata |awk '{print $2}'
do
sudo umount $fs
done";i:1;N;i:2;N;}i:2;i:14539;}i:227;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:14619;}i:228;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:14619;}i:229;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:14619;}i:230;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:14619;}i:231;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:87:" Deactivate all the LVs that has the sapdata filesystems and finally change the VG Name";}i:2;i:14623;}i:232;a:3:{i:0;s:4:"code";i:1;a:3:{i:0;s:45:"lvchange -a n LV NAME
vgrename sapvg oldsapvg";i:1;N;i:2;N;}i:2;i:14715;}i:233;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:14768;}i:234;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:14768;}i:235;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:14768;}i:236;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:14768;}i:237;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:55:" Edit the /etc/fstab file and comment out the sapdatas ";}i:2;i:14772;}i:238;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:14827;}i:239;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:14827;}i:240;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:14827;}i:241;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:14827;}i:242;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:1:" ";}i:2;i:14831;}i:243;a:3:{i:0;s:12:"internallink";i:1;a:2:{i:0;s:32:"unix:powercli_resignature_rename";i:1;s:21:"Resignature the Disks";}i:2;i:14832;}i:244;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:59:" that Storage Team has presented and rename them if needed.";}i:2;i:14890;}i:245;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:14949;}i:246;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:14949;}i:247;a:3:{i:0;s:13:"listitem_open";i:1;a:1:{i:0;i:1;}i:2;i:14949;}i:248;a:3:{i:0;s:16:"listcontent_open";i:1;a:0:{}i:2;i:14949;}i:249;a:3:{i:0;s:5:"cdata";i:1;a:1:{i:0;s:391:" In this case, since the source sapdatas were distributed across 6 datastores, we decided to consolidate all sapdata disks into two new datastores.  So, Storage Team had also presented two new datastores to the cluster.  Name the datastores according to the proper standard and vmotion the vmdks from the snapped-datastore to the new datastore. This can be done using the PowerCLI.  <code>  ";}i:2;i:14953;}i:250;a:3:{i:0;s:17:"listcontent_close";i:1;a:0:{}i:2;i:15344;}i:251;a:3:{i:0;s:14:"listitem_close";i:1;a:0:{}i:2;i:15344;}i:252;a:3:{i:0;s:11:"listo_close";i:1;a:0:{}i:2;i:15344;}i:253;a:3:{i:0;s:13:"section_close";i:1;a:0:{}i:2;i:15344;}i:254;a:3:{i:0;s:12:"document_end";i:1;a:0:{}i:2;i:15344;}}